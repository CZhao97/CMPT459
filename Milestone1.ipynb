{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import json\n",
    "import zipfile\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy import ndimage\n",
    "import descartes\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import googlemaps\n",
    "import gmaps\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "porter = PorterStemmer()\n",
    "lancaster=LancasterStemmer()\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc: plot histogram according to the param Series and a name \n",
    "def histplot(data, name=None, title=None, kde_flag=True, hist_kws=None):\n",
    "    plt.figure(figsize = (6,4))\n",
    "    sns.distplot(data, kde=kde_flag, hist_kws=hist_kws).set(xlabel = name +\" histogram\", title = title)\n",
    "    \n",
    "# desc: use RE to filter (clean) text features for further processing (ie. stemming)  \n",
    "def clean_text(list_t):\n",
    "    temp = []\n",
    "    for text in list_t:\n",
    "        # remove backslash-apostrophe \n",
    "        text = re.sub(\"\\'\", \"\", text) \n",
    "        # remove everything except alphabets \n",
    "        text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "        # remove whitespaces \n",
    "        text = ' '.join(text.split()) \n",
    "        # convert text to lowercase \n",
    "        text = text.lower() \n",
    "        temp.append(text)\n",
    "    \n",
    "    return temp\n",
    "\n",
    "# desc: find outliers from data according to a threshold, return their indeces\n",
    "def findOutlierIndex(data, threshold):\n",
    "    z = np.abs(stats.zscore(data))\n",
    "    index_outliers = np.where(z > threshold)\n",
    "    return index_outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from zip file\n",
    "d = None  \n",
    "data = None  \n",
    "with zipfile.ZipFile(\"train.json.zip\", \"r\") as z:\n",
    "   for filename in z.namelist():    \n",
    "      with z.open(filename) as f:  \n",
    "         data = f.read()  \n",
    "         d = json.loads(data.decode(\"utf-8\"))\n",
    "        \n",
    "data = pd.DataFrame.from_dict(d)\n",
    "\n",
    "rental_train = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Exploratory data analysis(Use the training dataset to perform EDA)</b>\n",
    "*   Plot histograms for the following numeric columns: Price, Latitude & Longitude. \n",
    "*   Plot hour-wise listing trend and find out the top 5 busiest hours of postings. \n",
    "*   Visualization to show the proportion of target variable values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(rental_train.shape)\n",
    "numOfRow = rental_train.shape[0]\n",
    "# clean price\n",
    "price_front_percentile = np.percentile(rental_train.price, 0.5)\n",
    "price_end_percentile = np.percentile(rental_train.price, 99.5)\n",
    "price_clean = rental_train[(rental_train['price'] < np.int(price_end_percentile)) & (rental_train['price'] > np.int(price_front_percentile))]\n",
    "\n",
    "price_clean = price_clean['price']\n",
    "\n",
    "# clean lat&lon\n",
    "lat_up = 40.95\n",
    "lat_down = 40.5\n",
    "lon_left = -74.1\n",
    "lon_right = -73.8\n",
    "\n",
    "lat_clean = rental_train[ (lat_up >= rental_train['latitude']) & (rental_train['latitude'] >= lat_down)]\n",
    "lon_clean = rental_train[ (lon_right >= rental_train['longitude']) & (rental_train['longitude'] >= lon_left)]\n",
    "lat_lon_clean = rental_train[ (lat_up >= rental_train['latitude']) & (rental_train['latitude'] >= lat_down) & (lon_right >= rental_train['longitude']) & (rental_train['longitude'] >= lon_left)]\n",
    "print(\"number of records cleaned out by lat: \", numOfRow-lat_clean.shape[0])\n",
    "print(\"number of records cleaned out by lon: \", numOfRow-lon_clean.shape[0])\n",
    "print(\"number of records cleaned out by lat and lon: \", numOfRow-lat_lon_clean.shape[0])\n",
    "\n",
    "\n",
    "lat_clean = lat_clean['latitude']\n",
    "lon_clean = lon_clean['longitude']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Plot histograms for the following numeric columns: Price, Latitude & Longitude.\n",
    "sns.distplot(np.clip(rental_train[\"price\"], 0, 15000), bins=333, color='b', hist_kws=dict(alpha=0.5)).set(xlabel = \"price histogram\", title='Price histogram before clean, but put right outliers in one bin')\n",
    "\n",
    "histplot(price_clean, name='price', title='Price histogram after clean out front and end 0.5%')\n",
    "# histplot(lat_clean, 'latitude')\n",
    "# histplot(lon_clean, 'longitude')\n",
    "\n",
    "histplot(lat_lon_clean['latitude'], 'latitude')\n",
    "histplot(lat_lon_clean['longitude'], 'longitude')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Plot hour-wise listing trend and find out the top 5 busiest hours of postings. \n",
    "rental_train['created'] = pd.to_datetime(rental_train['created'])\n",
    "# rental_train.iloc[0]['created']\n",
    "rental_train['created_hour'] = rental_train['created'].dt.hour\n",
    "histplot(rental_train['created'].dt.hour, 'hour', False)\n",
    "\n",
    "# counts_df = pd.Series(range(24))\n",
    "counts = np.zeros(24)\n",
    "for i in range(rental_train.shape[0]):\n",
    "    counts[rental_train.iloc[i]['created'].hour-1] += 1 \n",
    "counts = pd.Series(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.index = np.arange(1, len(counts)+1)\n",
    "print(\"the top 5 busiest hours of postings:\\ntime counts\")\n",
    "print(counts.nlargest(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.Visualization to show the proportion of target variable values. \n",
    "rental_train_group = rental_train.groupby('interest_level')\n",
    "rental_train_group.size()\n",
    "interests = pd.DataFrame(rental_train_group.size())\n",
    "interests.columns = ['count']\n",
    "interests.plot.pie(y='count',figsize=(8,10),fontsize=20,autopct='%1.1f%%')\n",
    "plt.title('PieChart of Interest Level', fontsize=20)\n",
    "\n",
    "plt.figure(figsize = (6,4))\n",
    "index = pd.Series.tolist(interests.index)\n",
    "value = pd.Series.tolist(rental_train_group.size())\n",
    "y_pos = np.arange(len(index))\n",
    "plt.bar(y_pos, value)\n",
    "plt.xticks(y_pos, index,fontsize=15)\n",
    "plt.ylabel('counts')\n",
    "plt.title('Barplot of Interest Level', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*4.Extract prices of each interest level and visaulize them accordingly\n",
    "\n",
    "# before excluding price outliers\n",
    "print(\"Price before excluding price outliers:\\n\",rental_train_group.agg({'price':['min','max','mean']}),\"\\n\")\n",
    "\n",
    "# after cleaning\n",
    "price_front_percentile = np.percentile(rental_train.price, 0.5)\n",
    "price_end_percentile = np.percentile(rental_train.price, 99.5)\n",
    "\n",
    "price_clean = rental_train[(rental_train['price'] < np.int(price_end_percentile)) & (rental_train['price'] > np.int(price_front_percentile))]\n",
    "print(\"Price after excluding price outliers:\\n\",price_clean.groupby('interest_level').agg({'price':['min','max','mean']}))\n",
    "\n",
    "# separated histograms of prices after cleaning\n",
    "high = price_clean[price_clean['interest_level']=='high']\n",
    "low = price_clean[price_clean['interest_level']=='low']\n",
    "medium = price_clean[price_clean['interest_level']=='medium']\n",
    "\n",
    "sns.distplot(high['price'], color='b', kde=False, hist_kws=dict(alpha=1))\n",
    "sns.distplot(low['price'], color='g', kde=False, hist_kws=dict(alpha=0.1))\n",
    "sns.distplot(medium['price'], color='r', kde=False, hist_kws=dict(alpha=0.3)).legend(['high','low','medium'])\n",
    "\n",
    "# plt.figure(figsize = (6,4))\n",
    "# sns.boxplot(x='interest_level', y='price', data=rental_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize each record on a google map of NYC\n",
    "import gmaps\n",
    "\n",
    "with open('API_key.txt') as f:\n",
    "    api_key = f.readline()\n",
    "    f.close\n",
    "\n",
    "gmaps_key = googlemaps.Client(key=api_key)\n",
    "\n",
    "lat_lon_clean = lat_lon_clean[['latitude', 'longitude']]\n",
    "\n",
    "sample_coordinates = lat_lon_clean.sample(frac=0.05, replace=False, random_state=1)\n",
    "\n",
    "gmaps.configure(api_key=api_key)\n",
    "\n",
    "lat_lon_layer = gmaps.symbol_layer(\n",
    "    sample_coordinates, fill_color='green', stroke_color='green', scale=2\n",
    ")\n",
    "fig = gmaps.figure()\n",
    "fig.add_layer(lat_lon_layer)\n",
    "fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Dealing with missing values,outliers</b>\n",
    "*    Find out the number of missing values in each variable. \n",
    "*    Find out the number of outliers in each variable. Plot visualizations to\n",
    "    demonstrate them.You can either remove the outliers or provide a\n",
    "    short argument as to why outlier detection is not meaningful for that attribute. \n",
    "*    Can we safely drop the missing values? If not, how will you deal withthem? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    1.Find out the number of missing values in each variable.\n",
    "    2.Find out the number of outliers in each variable. \n",
    "      Plot visualizations to demonstrate them.\n",
    "      You can either remove the outliers or provide a short argument as to why outlier detection is not meaningful for that attribute.\n",
    "    3.Can we safely drop the missing values? If not, how will you deal withthem?\n",
    "'''\n",
    "\n",
    "# zero bath/bedroom value would not be considered as \"missing\", \n",
    "# and possible outliers are reansonalbe therefore not dropped\n",
    "bath_bed_missing = rental_train[(rental_train['bathrooms'] == 0.0) | (rental_train['bedrooms'] == 0.0)]\n",
    "print(\"Number of missing values in either zero bathrooms or zero bedrooms:\", len(bath_bed_missing))\n",
    "\n",
    "# missing value of buildingID would not be dropped, as they can be recovered, or they are somewhat irrelavant \n",
    "# (and no numerical outliers)\n",
    "buildingID_missing = rental_train[rental_train['building_id'] == \"0\"]\n",
    "print(\"Number of missing values in buildingID:\", len(buildingID_missing))\n",
    "\n",
    "# created_hour have no missing data\n",
    "# and possible outliers are reansonalbe therefore not dropped\n",
    "created_hour_missing = rental_train[rental_train['created_hour'] == None]\n",
    "print(\"Number of missing values in created_hour:\", len(created_hour_missing))\n",
    "\n",
    "# outliers & missing values in lat/longitude could be fixed by street address therefore not dropped\n",
    "lat_lon_missing = rental_train[(rental_train['latitude']==0.0) | (rental_train['longitude']==0.0)]\n",
    "print(\"Number of missing values in either zero latitude or zero longitude:\", len(lat_lon_missing))\n",
    "\n",
    "#sns.scatterplot(x='latitude', y='longitude', data=rental_train).set(title='lat/longitude scatterplot')\n",
    "plt.scatter(rental_train['latitude'], rental_train['longitude'],marker='.')\n",
    "plt.title('lat/longitude scatterplot')\n",
    "\n",
    "# ManagerID have no missing data\n",
    "# (and no numerical outliers)\n",
    "# (considering to extract names from these IDs)\n",
    "managerID_missing = rental_train[rental_train['manager_id'] == '0']\n",
    "print(\"Number of missing values in managerID:\", len(managerID_missing))\n",
    "#print(rental_train.groupby('manager_id').count())\n",
    "\n",
    "# price have no missing data, \n",
    "# but the outlier could be dropped as intuitively, they would contribute very little to the classifier\n",
    "price_missing = rental_train[rental_train['price'] == 0]\n",
    "print(\"Number of missing values in price:\", len(price_missing))\n",
    "print(\"Number of price outliers:\", numOfRow-len(price_clean))\n",
    "\n",
    "# Other missing values(and possible outliers) in text (ie, address, description) would be further processed\n",
    "# so that they could be decided to drop or not. \n",
    "# (Mostly not, as shown in the next step that no value would not be considered as missing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following are the statistical(according to Z-score) outliers of lat, lon, and price \n",
    "Outlier_indexlist = findOutlierIndex(rental_train['latitude'], 1.5)\n",
    "print(\"\\nLatitude outliers (threshold 1.5):\\ntotal number: \", len(Outlier_indexlist[0]), \"\\nIndex     value\")\n",
    "print(rental_train.ix[Outlier_indexlist]['latitude'])\n",
    "\n",
    "Outlier_indexlist = findOutlierIndex(rental_train['longitude'], 1.5)\n",
    "print(\"\\nLongitude outliers (threshold 1.5):\\ntotal number: \", len(Outlier_indexlist[0]), \"\\nIndex     value\")\n",
    "print(rental_train.ix[Outlier_indexlist]['longitude'])\n",
    "\n",
    "Outlier_indexlist = findOutlierIndex(rental_train['price'], 0.5)\n",
    "print(\"\\nPrice outliers (threshold 0.5):\\ntotal number: \", len(Outlier_indexlist[0]), \"\\nIndex     value\")\n",
    "print(rental_train.ix[Outlier_indexlist]['price'])\n",
    "rental_train.ix[Outlier_indexlist].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_train = rental_train.drop(rental_train.ix[Outlier_indexlist].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b> Feature extraction from images and text</b>\n",
    "*  Extract features from the images and transform it into data that’s ready to be\n",
    "    used in the model for classification.\n",
    "*  Extract features from the text data and transform it into data that’s ready to be\n",
    "    used in the model for classification. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Extract features from the images and transform it into data that’s ready to be used in the model for classification.\n",
    "\n",
    "# Get number of photos of each rental posting \n",
    "def count_num_photos(photo_list):\n",
    "    return len(photo_list)\n",
    "\n",
    "rental_train['num_photos'] = rental_train['photos'].apply(count_num_photos)\n",
    "rental_train.head()\n",
    "\n",
    "# Other approaches are in the Logo_extraction.ipynb and is briefly discussed in report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Extract features from the text data and transform it into data that’s ready to be used in the model for classification. \n",
    "\n",
    "data['features'] = data['features'].apply(lambda x : clean_text(x))\n",
    "\n",
    "ps = PorterStemmer()\n",
    "def porter_stemmer(list_t):\n",
    "    temp = []\n",
    "    for i in list_t:\n",
    "        temp.append(ps.stem(i))\n",
    "    return temp\n",
    "\n",
    "data['stemmed_features'] = data['features'].apply(porter_stemmer)\n",
    "\n",
    "dic = {}\n",
    "for i in range(len(data)):\n",
    "    for j in data[\"stemmed_features\"][i]:\n",
    "        if j in dic:\n",
    "            dic[j]+=1\n",
    "        else:\n",
    "            dic.setdefault(j,1)\n",
    "            \n",
    "dic = {key:val for key, val in dic.items() if val > 5000}\n",
    "values = dic.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.boxplot(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = list(dic.keys())\n",
    "\n",
    "for i in keys:\n",
    "    data[i] = 0\n",
    "    \n",
    "for index,words in enumerate(data['stemmed_features']):\n",
    "    for i in words:\n",
    "        if i in keys:\n",
    "            data[i][index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features extracted from text, stored as binary values in the last 15 columns \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.axes[1][0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
